For the last couple of weeks I've been upping out data collection at my startup. Up to now, we've been using log files for logging and datadog for metrics.

Datadog is a great product, and it has served us very well. That said I've decided to move to our own graphite / statsd based stack since Datadog:

- Has no easy way to get your entire data out. Maybe you want to run some very especific analysis  over it. Maybe your moving to something else. I cannot, with an easy consciense choose a data service that won't let me part with my data. I know that it would be tricky, but it's doable. Here's an idea: export to whisper or rdd. Charge per export run and per gigabyte (since an export can be expensive).

-  Has no way to import historical data. I frequently decide to track something and I need to look at it's evolution as early as I can. Yes, some data is ephemeral, and won't be available since you've never collected. Other times, however, you can generate historcial data. This is often the case for business metrcis, say the number of orders from corporate vs personal accounts. It's very unflexible. When you're talking data, you want to be as flexible as you can, because what to track might take you a while to figure out.
- Cost. I do think their pricing is fair, and I know they're cheaper than most of the other players. While we still operate on a small scale we do have quite a few number of boxes (over twenty). It makes for better resilience and architecture to divide your infrastructure into many boxes, as opessed to a few large ones. While not a deal breaker per se, it adds up. Also, the pricing per host kind of breaks down when using containers. We are happy docker users, and having a price per docker instance would make it prohibitively expansive. In their defense, not charging per metric is awesome, else you will likely measure less than you'd like, and that's bad. These days, 20 bucks per month will get you enough juice to process a whole lot of stuff. Machines are cheap now.

